{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from keras.layers import BatchNormalization, LayerNormalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from dataset_config.ipynb\n",
      "Found 0 images belonging to 13 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from dataset_config import create_first_data_flow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet import ResNet101"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# incomplete because we need to generate a better dataset for training\n",
    "train_data = 1\n",
    "test_data = 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "  def __init__(self, train_data, test_data, verbose=False):\n",
    "    self.train_data = train_data\n",
    "    self.test_data = test_data\n",
    "\n",
    "    self.train_log = {}\n",
    "    self.test_log = {}\n",
    "    self.verbose = verbose\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    x_train, y_train = self.train_data\n",
    "    x_test, y_test = self.test_data\n",
    "\n",
    "    train_loss, train_acc = self.model.evaluate(x_train, y_train, batch_size=32, verbose=0)\n",
    "    test_loss, test_acc = self.model.evaluate(x_test, y_test, batch_size=32,  verbose=0)\n",
    "\n",
    "    self.train_log[epoch] = train_acc\n",
    "    self.test_log[epoch] = test_acc\n",
    "\n",
    "    if self.verbose == True:\n",
    "      log = 'E: {} - Train - Test loss: {} - {}, acc: {} - {}'.format(\n",
    "              epoch, train_loss, test_loss, train_acc, test_acc)\n",
    "      print(log)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def init_resnet_arch(resnet_model):\n",
    "    model = Sequential()\n",
    "    model.add(resnet_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation=('relu')))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.4))\n",
    "    model.add(Dense(512, activation=('relu')))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.4))\n",
    "    model.add(Dense(256, activation=('relu')))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.4))\n",
    "    model.add(Dense(128, activation=('relu')))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.4))\n",
    "    model.add(Dense(10, activation=('softmax')))\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def resnet_model_compile():\n",
    "    model_resnet = ResNet50(include_top=False, weights='imagenet', input_shape=(800,800,3), classes=train_data.shape[1])\n",
    "    model_resnet_sgd = init_resnet_arch(model_resnet)\n",
    "\n",
    "    # 391 steps per epoch-- 7 * 391 = 2737 steps\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate = 1e-2,\n",
    "        decay_steps = 2730,\n",
    "        decay_rate = 0.7)\n",
    "\n",
    "    # 1e-2 the default value for SGD and 1e-3 default value for Adam\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "    model_resnet_sgd.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    baseline_callbacks = [TestCallback(train_data, test_data)]\n",
    "    fit_res = model_resnet.fit(train_data, test_data, epochs=30, callbacks=baseline_callbacks, batch_size=128, verbose=False)\n",
    "    return fit_res"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
