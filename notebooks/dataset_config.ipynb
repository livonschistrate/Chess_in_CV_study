{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_dataset_path = '../datasets/dataset 1'\n",
    "second_dataset_path = '../datasets/dataset 2'\n",
    "piece_images_path = 'processed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['test', 'train', 'val']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "os.listdir(second_dataset_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shuffle_data = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# First dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# data proportions\n",
    "TRAIN_DATA = 0.7\n",
    "TEST_DATA = 0.15\n",
    "VAL_DATA = 0.15\n",
    "\n",
    "# sizes used in training\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# factor of increasing the cropped version of images\n",
    "IMAGE_GROWTH_FACTOR = 0.1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# loading config variables: types of pieces and cell coordinates\n",
    "dataset_path = first_dataset_path + '/data'\n",
    "config = json.load(open(dataset_path + '/config.json', \"r\"))\n",
    "piecesTypes = config['piecesTypes']\n",
    "cellsCoordinates = config['cellsCoordinates']\n",
    "piecesTypes.append('empty')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "minCoords = np.array([np.inf, np.inf])\n",
    "maxCoords = np.array([-np.inf, -np.inf])\n",
    "for cell in cellsCoordinates:\n",
    "    minCoords = np.minimum(minCoords, cellsCoordinates[cell])\n",
    "    maxCoords = np.maximum(maxCoords, cellsCoordinates[cell])\n",
    "boardSize = (maxCoords - minCoords + np.array([1, 1])).astype(int)\n",
    "marginSize = np.array([1, 1]) * IMAGE_SIZE * IMAGE_GROWTH_FACTOR\n",
    "cellSize = (IMAGE_SIZE - marginSize) / boardSize\n",
    "relativeCellSize = (1 - IMAGE_GROWTH_FACTOR) / boardSize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'A1': [0, 0],\n 'A2': [0, 1],\n 'A3': [0, 2],\n 'A4': [0, 3],\n 'A5': [0, 4],\n 'A6': [0, 5],\n 'A7': [0, 6],\n 'A8': [0, 7],\n 'B1': [1, 0],\n 'B2': [1, 1],\n 'B3': [1, 2],\n 'B4': [1, 3],\n 'B5': [1, 4],\n 'B6': [1, 5],\n 'B7': [1, 6],\n 'B8': [1, 7],\n 'C1': [2, 0],\n 'C2': [2, 1],\n 'C3': [2, 2],\n 'C4': [2, 3],\n 'C5': [2, 4],\n 'C6': [2, 5],\n 'C7': [2, 6],\n 'C8': [2, 7],\n 'D1': [3, 0],\n 'D2': [3, 1],\n 'D3': [3, 2],\n 'D4': [3, 3],\n 'D5': [3, 4],\n 'D6': [3, 5],\n 'D7': [3, 6],\n 'D8': [3, 7],\n 'E1': [4, 0],\n 'E2': [4, 1],\n 'E3': [4, 2],\n 'E4': [4, 3],\n 'E5': [4, 4],\n 'E6': [4, 5],\n 'E7': [4, 6],\n 'E8': [4, 7],\n 'F1': [5, 0],\n 'F2': [5, 1],\n 'F3': [5, 2],\n 'F4': [5, 3],\n 'F5': [5, 4],\n 'F6': [5, 5],\n 'F7': [5, 6],\n 'F8': [5, 7],\n 'G1': [6, 0],\n 'G2': [6, 1],\n 'G3': [6, 2],\n 'G4': [6, 3],\n 'G5': [6, 4],\n 'G6': [6, 5],\n 'G7': [6, 6],\n 'G8': [6, 7],\n 'H1': [7, 0],\n 'H2': [7, 1],\n 'H3': [7, 2],\n 'H4': [7, 3],\n 'H5': [7, 4],\n 'H6': [7, 5],\n 'H7': [7, 6],\n 'H8': [7, 7]}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellsCoordinates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['bishop_b',\n 'bishop_w',\n 'king_b',\n 'king_w',\n 'knight_b',\n 'knight_w',\n 'pawn_b',\n 'pawn_w',\n 'queen_b',\n 'queen_w',\n 'rook_b',\n 'rook_w',\n 'empty']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piecesTypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_labels_per_board(file_nr):\n",
    "    json_file = json.load(open(str(file_nr) + '.json'))\n",
    "    json_board = {}\n",
    "    X_train, Y_train = [], []\n",
    "    all_spaces = cellsCoordinates.keys()\n",
    "    for space, piece in json_file['config']:\n",
    "        if space not in all_spaces:\n",
    "            json_board[space] = 'empty'\n",
    "        else:\n",
    "            json_board[space] = piece\n",
    "    small_img = [filename for filename in os.listdir(piece_images_path) if filename.startswith(str(file_nr))]\n",
    "    for space, filename in zip(all_spaces, small_img):\n",
    "        X_train.append(cv.imread(filename))\n",
    "        Y_train.append(space)\n",
    "    return X_train, Y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def create_first_data_flow():\n",
    "    train_generator = ImageDataGenerator(rescale=1/255).flow_from_directory(\n",
    "        piece_images_path,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        target_size=(280, 280),\n",
    "        shuffle=True,\n",
    "        classes=piecesTypes,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    valid_generator = ImageDataGenerator(rescale=1/255).flow_from_directory(\n",
    "        piece_images_path,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        target_size=(280, 280),\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    return (train_generator, valid_generator)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 13 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": "(<keras.src.legacy.preprocessing.image.DirectoryIterator at 0x21a02e5c070>,\n <keras.src.legacy.preprocessing.image.DirectoryIterator at 0x21a02e08a30>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_first_data_flow()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Second dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# loading datasets\n",
    "train_data_path_second = second_dataset_path + '/train'\n",
    "test_data_path_second = second_dataset_path + '/test'\n",
    "val_data_path_second = second_dataset_path + '/val'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
